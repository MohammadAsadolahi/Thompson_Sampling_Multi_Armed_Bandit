# Thompson_Sampling_Multi_Armed_Bandit
NumPy implementation of Thompson Sampling for K-actions stochastic bandit with a normal reward distribution  
Further Optimal Regret Bounds for Thompson Sampling by Shipra Agrawal, Navin Goyal is also implemented  
https://arxiv.org/abs/1209.3353  
![4 arms bandit for horizon 100 using thomson sampling](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit.png)
![2 arms bandit for horizon 100 using thomson sampling σ2 = 0.25 and μ is uniformly sampled in the interval [0, 10]](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit%20%CF%832%20%3D%200.25%20and%20%CE%BCk%20uniformly%20sampled%20in%20the%20interval%20%5B0.0%2C%201.0%5D.png)
![4 arms bandit for horizon 100 using thomson sampling](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit.png)
![4 arms bandit for horizon 100 using thomson sampling](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit.png)
![4 arms bandit for horizon 100 using thomson sampling](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit.png)
