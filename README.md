# Thompson Sampling Multi-Armed Bandit
NumPy implementation of Thompson Sampling for K-actions stochastic bandit with a normal reward distribution  
Further Optimal Regret Bounds for Thompson Sampling by Shipra Agrawal, Navin Goyal is also implemented  
https://arxiv.org/abs/1209.3353
### 4 arms bandit for horizon 100 using Thompson sampling:
![4 arms bandit for horizon 100 using Thompson sampling](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit.png)
### 2 arms bandit for horizon 100 using Thompson sampling σ2 = 0.25 and μ is uniformly sampled in the interval [0, 10]:
![2 arms bandit for horizon 100 using Thompson sampling σ2 = 0.25 and μ is uniformly sampled in the interval [0, 10]](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/Normal%20distribution%203%20arm%20bandit%20%CF%832%20%3D%200.25%20and%20%CE%BCk%20uniformly%20sampled%20in%20the%20interval%20%5B0.0%2C%201.0%5D.png)
### TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =0
![TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =0](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/TS-Normal%20strategy%20for%202%20arm%20bandit%20m%20%3D0%20.png)
### TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =5
![TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =5](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/TS-Normal%20strategy%20for%202%20arm%20bandit%20m%20%3D5%20.png)
### TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =10
![TS-Normal strategy by Agrawal & Goyal - 2 arm bandit m =10](https://github.com/MohammadAsadolahi/Thompson_Sampling_Multi_Armed_Bandit/blob/main/TS-Normal%20strategy%20for%202%20arm%20bandit%20m%20%3D10%20.png)
